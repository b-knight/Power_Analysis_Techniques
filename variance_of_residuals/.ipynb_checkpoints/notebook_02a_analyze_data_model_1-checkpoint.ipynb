{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_size_rec(data_src, data_labels, rejection_region, desired_power):\n",
    "    \n",
    "    import random\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    \n",
    "    data_src.columns = data_labels\n",
    "    \n",
    "    absolute_mde = data_src[data_src['Treated'] == 1]['Order_Amt'].mean() - \\\n",
    "                   data_src[data_src['Treated'] == 0]['Order_Amt'].mean()\n",
    "\n",
    "    \n",
    "    print(\"The absolute MDE was estimated as {}.\".format(absolute_mde))\n",
    "    \n",
    "    df = data_src[data_src['Treated'] == 0]\n",
    "    assignment = []\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        assignment.append(random.randint(0,1)) \n",
    "        i += 1\n",
    "    df['Partition'] = assignment\n",
    "    power_analysis_df = df[df['Partition'] == 0]\n",
    "    analysis_df = df[df['Partition'] == 1]\n",
    "        \n",
    "    del df\n",
    "    \n",
    "    pa_retailer_means = pd.DataFrame(power_analysis_df.groupby(['Retailer_ID'])['Order_Amt'].mean())\n",
    "    pa_retailer_means.reset_index(inplace=True)\n",
    "    pa_retailer_means.columns = ['Retailer_ID', 'Mean_Retailer_Order_Amt']\n",
    "    ###############################################################################\n",
    "    pa_dow_means = pd.DataFrame(power_analysis_df.groupby(['Dow_Rand'])['Order_Amt'].mean())\n",
    "    pa_dow_means.reset_index(inplace=True)\n",
    "    pa_dow_means.columns = ['Dow_Rand', 'Mean_DOW_Order_Amt']\n",
    "    ###############################################################################\n",
    "    analysis_df = pd.merge(analysis_df, pa_retailer_means, on='Retailer_ID', how='left')\n",
    "    analysis_df = pd.merge(analysis_df, pa_dow_means, on='Dow_Rand', how='left')\n",
    "    ###############################################################################\n",
    "    analysis_df = analysis_df[['Order_Amt', 'Customer_ID', 'Mean_Order_Amt', \n",
    "                               'Mean_Retailer_Order_Amt','Mean_DOW_Order_Amt']]\n",
    "    \n",
    "    X = analysis_df[['Mean_Order_Amt', 'Mean_Retailer_Order_Amt','Mean_DOW_Order_Amt']]\n",
    "    X = sm.add_constant(X)\n",
    "    Y = analysis_df[['Order_Amt']]\n",
    "    residuals_df = sm.OLS(Y.astype(float), X.astype(float)).fit()\n",
    "    \n",
    "    X2 = analysis_df[['Customer_ID']]\n",
    "    X2['Residual'] = residuals_df.resid\n",
    "    X2['Constant'] = 1\n",
    "    clustered_res = sm.OLS(X2['Residual'], X2['Constant']).fit(method='pinv'). \\\n",
    "                       get_robustcov_results('cluster', groups = X2['Customer_ID'], \n",
    "                       use_correction=True, df_correction=True)\n",
    "    \n",
    "    clustered_sd = clustered_res.bse[0] * np.sqrt(analysis_df.shape[0])\n",
    "    effect_size = absolute_mde / clustered_sd\n",
    "    recommended_n = int(sm.stats.tt_ind_solve_power(effect_size = effect_size, \n",
    "                        alpha = rejection_region, power = desired_power, \n",
    "                        alternative = 'larger'))\n",
    "    print(\"A sample size of {} was recommended.\".format(recommended_n ))\n",
    "    return recommended_n, absolute_mde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_sample_size_est(sample_size, data_src, data_labels, alpha, verify_n_times):\n",
    "\n",
    "    import statsmodels.api as sm\n",
    "    import pandas as pd\n",
    "    \n",
    "    SAMPLE_SIZE = sample_size\n",
    "    VERIFICATION_ITERATIONS = verify_n_times\n",
    "    ALPHA = alpha\n",
    "\n",
    "    i = 0\n",
    "    pvals  = []\n",
    "    r_sqr  = []\n",
    "    cond_n = []\n",
    "    while i < VERIFICATION_ITERATIONS:\n",
    "        working_df = data_src.sample(SAMPLE_SIZE, replace=False)\n",
    "        ###############################################################################\n",
    "        pa_retailer_means = pd.DataFrame(working_df.groupby(['Retailer_ID'])['Order_Amt'].mean())\n",
    "        pa_retailer_means.reset_index(inplace=True)\n",
    "        pa_retailer_means.columns = ['Retailer_ID', 'Mean_Retailer_Order_Amt']\n",
    "        ###############################################################################\n",
    "        pa_dow_means = pd.DataFrame(working_df.groupby(['Dow_Rand'])['Order_Amt'].mean())\n",
    "        pa_dow_means.reset_index(inplace=True)\n",
    "        pa_dow_means.columns = ['Dow_Rand', 'Mean_DOW_Order_Amt']\n",
    "        ###############################################################################\n",
    "        analysis_df = pd.merge(working_df, pa_retailer_means, on='Retailer_ID', how='left')\n",
    "        analysis_df = pd.merge(analysis_df, pa_dow_means, on='Dow_Rand', how='left')\n",
    "        ###############################################################################\n",
    "        analysis_df = analysis_df[['Order_Amt', 'Customer_ID', 'Treated', 'Mean_Order_Amt', \n",
    "                                 'Mean_Retailer_Order_Amt','Mean_DOW_Order_Amt']]\n",
    "        ###############################################################################\n",
    "        X = analysis_df[['Treated', 'Mean_Order_Amt', 'Mean_Retailer_Order_Amt','Mean_DOW_Order_Amt']]\n",
    "        X = sm.add_constant(X)\n",
    "        Y = analysis_df[['Order_Amt']]\n",
    "        model = sm.OLS(Y.astype(float), X.astype(float)).fit(method='pinv'). \\\n",
    "                       get_robustcov_results('cluster', groups = analysis_df['Customer_ID'], \n",
    "                       use_correction=True, df_correction=True)\n",
    "        if model.pvalues[1] < ALPHA: \n",
    "            pvals.append(1)\n",
    "        else:\n",
    "            pvals.append(0)  \n",
    "        r_sqr.append(model.rsquared_adj)\n",
    "        cond_n.append(model.condition_number)\n",
    "        i += 1\n",
    "        if i % int((VERIFICATION_ITERATIONS)/10.0) == 0:\n",
    "            completion = str(round((i/VERIFICATION_ITERATIONS)*100, 2))+'%'\n",
    "            print(completion + ' complete.')\n",
    "            \n",
    "    # ----- Exit inner loop     \n",
    "    x = ['Treated', 'Mean_Order_Amt', 'Mean_Retailer_Order_Amt','Mean_DOW_Order_Amt']\n",
    "    str_out = 'Order_Amt =' \n",
    "    d = 0\n",
    "    for i in x:\n",
    "        if d < 1:\n",
    "            k = \" '\" + i + \"'\"\n",
    "        else:\n",
    "            k = \" + '\" + i + \"'\"\n",
    "        str_out += k\n",
    "        d += 1    \n",
    "    \n",
    "    actual_power = sum(pvals)/len(pvals)  \n",
    "    mean_r_sqr   = sum(r_sqr)/len(r_sqr)   \n",
    "    mean_cond_n  = sum(cond_n)/len(cond_n)  \n",
    "    print(\"Actual power was estimated at {}.\".format(actual_power))\n",
    "    return actual_power, mean_r_sqr, mean_cond_n, str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_assess(sub_iterations, meta_iterations, alpha, target_power, \n",
    "                pa_file, analysis_file, file_name):\n",
    "\n",
    "    ALPHA = alpha\n",
    "    SUB_ITERATIONS = sub_iterations\n",
    "    META_ITERATIONS = meta_iterations\n",
    "    TARGET_POWER = target_power\n",
    "\n",
    "    dir = './residual_dfs/'\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    i = 0\n",
    "    results      = []\n",
    "    r_sqr_list   = []\n",
    "    cond_n_list  = []\n",
    "    abs_mde      = []\n",
    "    sample_sizes = []\n",
    "    while i < META_ITERATIONS:\n",
    "\n",
    "        data_src_a = pd.read_csv(dir + pa_file)\n",
    "        data_src_b = pd.read_csv(dir + analysis_file)\n",
    "        data_labels = ['Order_ID', 'Customer_ID', 'Mean_Order_Amt', 'Treated',\n",
    "                       'Treatment_Modifier', 'Retailer_ID', 'Retailer_Scalar',\n",
    "                       'Dow_Rand', 'DOW', 'Noise', 'Order_Amt']\n",
    "\n",
    "        recommended_n, absolute_mde = create_sample_size_rec(data_src_a, data_labels, \n",
    "                                               ALPHA, TARGET_POWER)\n",
    "\n",
    "        actual_power,r_sqr,mean_cond_n, str_out = verify_sample_size_est(recommended_n, data_src_b, \n",
    "                                                  data_labels, ALPHA, SUB_ITERATIONS)   \n",
    "\n",
    "        results.append(actual_power)\n",
    "        r_sqr_list.append(r_sqr)\n",
    "        cond_n_list.append(mean_cond_n)\n",
    "        abs_mde.append(absolute_mde)\n",
    "        sample_sizes.append(recommended_n)\n",
    "        i += 1\n",
    "        print(\"{} of {} iterations completed.\".format(i, META_ITERATIONS))\n",
    "    results                          = pd.DataFrame(results)    \n",
    "    results['Target Power']          = TARGET_POWER\n",
    "    results.columns                  = ['Achieved Power', 'Target Power']\n",
    "    results['Abs. MDE']              = absolute_mde\n",
    "    results['Model']                 = str_out\n",
    "    results['Delta']                 = results['Achieved Power'] - results['Target Power']\n",
    "    results['N']                     = sample_sizes\n",
    "    results['Mean_R_Sqr']            = r_sqr_list\n",
    "    results['Mean_Condition_Number'] = cond_n_list\n",
    "\n",
    "        # Save to .csv\n",
    "    if not os.path.exists('./residual_dfs/results'):\n",
    "        os.makedirs('./residual_dfs/results')\n",
    "    \n",
    "    results.to_csv('./residual_dfs/results/' + file_name)\n",
    "    print(\"{} was saved to disk.\".format('./residual_dfs/results/' + file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The absolute MDE was estimated as 0.1241636335615226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bknight/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/bknight/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/bknight/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample size of 45011 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.19.\n",
      "1 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 43942 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.188.\n",
      "2 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44422 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.154.\n",
      "3 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 43715 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.218.\n",
      "4 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 43558 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.172.\n",
      "5 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 43468 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.166.\n",
      "6 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44477 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.176.\n",
      "7 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44482 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.19.\n",
      "8 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44914 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.184.\n",
      "9 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44107 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.194.\n",
      "10 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 43391 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.162.\n",
      "11 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44368 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.206.\n",
      "12 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44669 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.214.\n",
      "13 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44292 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.182.\n",
      "14 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44551 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.186.\n",
      "15 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44356 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.19.\n",
      "16 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 43521 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.164.\n",
      "17 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44882 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.176.\n",
      "18 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44677 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.178.\n",
      "19 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 44487 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n",
      "50.0% complete.\n",
      "60.0% complete.\n",
      "70.0% complete.\n",
      "80.0% complete.\n",
      "90.0% complete.\n",
      "100.0% complete.\n",
      "Actual power was estimated at 0.174.\n",
      "20 of 100 iterations completed.\n",
      "The absolute MDE was estimated as 0.1241636335615226.\n",
      "A sample size of 43819 was recommended.\n",
      "10.0% complete.\n",
      "20.0% complete.\n",
      "30.0% complete.\n",
      "40.0% complete.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bbb4d6e79d16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m             \u001b[0;34m'part_II_df_mde_0_001_n_100000_a.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0;34m'part_II_df_mde_0_001_n_100000_b.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             'mde_0_001_n_100000_model_I.csv')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-50609c46955a>\u001b[0m in \u001b[0;36mmeta_assess\u001b[0;34m(sub_iterations, meta_iterations, alpha, target_power, pa_file, analysis_file, file_name)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         actual_power,r_sqr,mean_cond_n, str_out = verify_sample_size_est(recommended_n, data_src_b, \n\u001b[0;32m---> 31\u001b[0;31m                                                   data_labels, ALPHA, SUB_ITERATIONS)   \n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b84626c8fff4>\u001b[0m in \u001b[0;36mverify_sample_size_est\u001b[0;34m(sample_size, data_src, data_labels, alpha, verify_n_times)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pinv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                        get_robustcov_results('cluster', groups = analysis_df['Customer_ID'], \n\u001b[0;32m---> 36\u001b[0;31m                        use_correction=True, df_correction=True)\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mALPHA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mpvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36mget_robustcov_results\u001b[0;34m(self, cov_type, use_t, **kwds)\u001b[0m\n\u001b[1;32m   2216\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m                 res.cov_params_default = sw.cov_cluster(\n\u001b[0;32m-> 2218\u001b[0;31m                     self, groups, use_correction=use_correction)\n\u001b[0m\u001b[1;32m   2219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/statsmodels/stats/sandwich_covariance.py\u001b[0m in \u001b[0;36mcov_cluster\u001b[0;34m(results, group, use_correction)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptional_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'quicksort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meta_assess(500, 100, 0.05, 0.8, \n",
    "            'part_II_df_mde_0_05_n_100000_a.csv', \n",
    "            'part_II_df_mde_0_05_n_100000_b.csv', \n",
    "            'mde_0_05_n_100000_model_I.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# part_1_a = pd.read_csv('./residual_dfs/part_II_df_mde_0_001_n_100000_n.csv')\n",
    "# part_1_b = pd.read_csv('./residual_dfs/part_II_df_mde_0_001_n_100000_a_1.csv')\n",
    "# df = pd.concat([part_1_a, part_1_b])\n",
    "# df.to_csv('./residual_dfs/part_II_df_mde_0_001_n_600000_a.csv')\n",
    "\n",
    "# # 600000\n",
    "# 'part_II_df_mde_0_001_n_100000_a.csv'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
