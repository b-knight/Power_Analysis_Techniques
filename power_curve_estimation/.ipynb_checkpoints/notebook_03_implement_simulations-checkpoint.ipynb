{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_power(sample_sizes_to_eval, sub_iterations, meta_iterations,\n",
    "                p_value_threshold, desired_power, data, file_out): \n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "    import numpy as np\n",
    "    from scipy.optimize import curve_fit\n",
    "    import time    \n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    meta_results        = []\n",
    "    meta_supplement     = []\n",
    "    sub_iterations_list = []\n",
    "    \n",
    "    max_n = len(data)\n",
    "    \n",
    "    master_counter = 0\n",
    "    while master_counter < meta_iterations:\n",
    "        try:\n",
    "            master_results = []\n",
    "            for k in sample_sizes_to_eval:\n",
    "                counter = 0 \n",
    "                pvalues = []\n",
    "                while counter < sub_iterations:\n",
    "                    working_df = data.sample(k, replace=False)\n",
    "                    X = working_df.Treated\n",
    "                    X = sm.add_constant(X)\n",
    "                    Y = working_df.Order_Amt\n",
    "                    model = sm.OLS(Y, X).fit(method='pinv').get_robustcov_results(\n",
    "                            'cluster', groups = working_df.Customer_ID, \n",
    "                            use_correction=True, df_correction=True)\n",
    "                    pvalues.append(model.pvalues[1])\n",
    "                    counter += 1\n",
    "\n",
    "                results = []\n",
    "                for i in pvalues:\n",
    "                    if i <= p_value_threshold:\n",
    "                        results.append(1)    \n",
    "                    else:\n",
    "                        results.append(0)  \n",
    "                out = []\n",
    "                out.append(k)\n",
    "                out.append(p_value_threshold)\n",
    "                p_val = sum(results)/len(results)\n",
    "                print(p_val)\n",
    "                out.append(p_val) \n",
    "                master_results.append(out)\n",
    "\n",
    "            def exp_func(x, a, b, c):\n",
    "                return a * np.log(b * x) + c\n",
    "\n",
    "            eta = []\n",
    "            for i in master_results:\n",
    "                eta.append(i[0])\n",
    "            eta = np.asarray(eta)\n",
    "\n",
    "            cdf = []\n",
    "            for i in master_results:\n",
    "                cdf.append(i[2])\n",
    "            cdf = np.asarray(cdf)\n",
    "\n",
    "            popt, pcov = curve_fit(exp_func, eta, cdf)\n",
    "\n",
    "\n",
    "            recommended_n = int(np.exp((desired_power - popt[2])/popt[0])/popt[1])\n",
    "            if recommended_n > max_n:\n",
    "                recommended_n = max_n\n",
    "\n",
    "            print(\"The recommended sample size for a statistical power level of \" +\n",
    "                  \"{} is {}.\".format(desired_power, recommended_n))\n",
    "\n",
    "            final_pvalues = []\n",
    "            counter_2 = 0 \n",
    "            while counter_2 < 500:\n",
    "                if counter_2 % 50 == 0:                       \n",
    "                    print(\"Verification {} complete.\".format(round((counter_2/500), 2)))\n",
    "                working_df_2 = data.sample(recommended_n, replace=False)\n",
    "                X = working_df_2.Treated\n",
    "                X = sm.add_constant(X)\n",
    "                Y = working_df_2.Order_Amt\n",
    "                model_2 = sm.OLS(Y, X).fit(method='pinv').get_robustcov_results(\n",
    "                          'cluster', groups = working_df_2.Customer_ID, \n",
    "                          use_correction=True, df_correction=True)\n",
    "                final_pvalues.append(model_2.pvalues[1])\n",
    "                counter_2 += 1\n",
    "\n",
    "            final_results = []\n",
    "            for i in final_pvalues:\n",
    "                if i <= p_value_threshold:\n",
    "                    final_results.append(1)    \n",
    "                else:\n",
    "                    final_results.append(0)  \n",
    "\n",
    "            meta_results.append(sum(final_results)/len(final_results))\n",
    "            meta_supplement.append(desired_power)\n",
    "            sub_iterations_list.append(sub_iterations)\n",
    "            master_counter += 1\n",
    "            print(\"{} iterations sucessfully completed.\".format(master_counter))\n",
    "            end = time.time()\n",
    "            print(str(end - start) + ' time elapsed.')\n",
    "            \n",
    "        except:\n",
    "            print(\"Power curve inference failed.\")        \n",
    "        \n",
    "    df_out = pd.DataFrame(list(zip(meta_supplement, meta_results))) \n",
    "    df_out.columns = ['Desired Power', 'Actual Power']\n",
    "    df_out['Error'] = (df_out['Desired Power'] - df_out['Actual Power'])\n",
    "    df_out['Absolute Error'] =  df_out['Error'].abs()\n",
    "    df_out['Iterations'] = sub_iterations_list\n",
    "    total_iterations = (len(sample_sizes_to_eval)*sub_iterations)+500\n",
    "    df_out['Total Iterations'] = total_iterations\n",
    "    df_out.to_csv(file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37333333333333335\n",
      "0.5\n",
      "0.6\n",
      "The recommended sample size for a statistical power level of 0.8 is 17136.\n",
      "Verification 0.0 complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bknight/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in log\n",
      "/home/bknight/anaconda3/lib/python3.7/site-packages/scipy/optimize/minpack.py:794: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification 0.1 complete.\n",
      "Verification 0.2 complete.\n",
      "Verification 0.3 complete.\n",
      "Verification 0.4 complete.\n",
      "Verification 0.5 complete.\n",
      "Verification 0.6 complete.\n",
      "Verification 0.7 complete.\n",
      "Verification 0.8 complete.\n",
      "Verification 0.9 complete.\n",
      "1 iterations sucessfully completed.\n",
      "1126.7036168575287 time elapsed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_file_to_read = pd.read_csv('data_c_1000000_mde_01.csv')\n",
    "infer_power([6000, 8000,10000,12000,14000], 100, 1, 0.05, 0.8, data_file_to_read, 'test4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data_file_to_read = pd.read_csv('data_c_1000000_mde_01.csv')\n",
    "# infer_power([          8000,10000,12000],             300, 30, 0.05, 0.8, data_file_to_read, 'df7.csv')\n",
    "# print(\"DF 7 created.\")\n",
    "# infer_power([     6000,8000,10000,12000,14000],       300, 30, 0.05, 0.8, data_file_to_read, 'df8.csv')\n",
    "# print(\"DF 8 created.\")\n",
    "# infer_power([4000,6000,8000,10000,12000,14000,16000], 300, 30, 0.05, 0.8, data_file_to_read, 'df9.csv')\n",
    "# print(\"DF 9 created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
