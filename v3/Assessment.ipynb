{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bknight/anaconda3/lib/python3.7/site-packages/statsmodels/compat/pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from olsEmpowered import sim_data         as sd\n",
    "from olsEmpowered import power_estimation as pe\n",
    "from olsEmpowered import isotonic         as iso\n",
    "from olsEmpowered import binary_search    as bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 additional covariates will be created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bknight/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2223: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now performing OLS to infer DGP parameters.\n",
      "Simulation data was saved to: \n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/sim_data_2020_01_04_163104.csv.\n",
      "Meta-data was saved to: \n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/log_files/sim_data_2020_01_04_163104_log_file.txt.\n",
      "4500000 observations of simulation data created in 1 minutes and 54 seconds.\n",
      "Reconstituting data object from file.\n",
      "Successfully read in the .csv file specified at:\n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/sim_data_2020_01_04_163104.csv.\n",
      "/home/bknight/Documents/Power_Analysis_Techniques/v3/data/log_files/sim_data_2020_01_04_163104_log_file.txt\n",
      "Successfully read in the meta-data specified at:\n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/log_files/sim_data_2020_01_04_163104_log_file.txt.\n",
      "############## Starting value is n = 525,308.    ###########\n",
      "############## Starting adj. R-squared is 0.81. ###########\n",
      "/home/bknight/Documents/Power_Analysis_Techniques/v3/data\n",
      "The file sim_data_2020_01_04_163104.csv was deleted.\n",
      "The the associated meta-data for file sim_data_2020_01_04_163104.csv was also deleted.\n",
      "Starting value too high.\n",
      "5 additional covariates will be created.\n",
      "Now performing OLS to infer DGP parameters.\n",
      "Simulation data was saved to: \n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/sim_data_2020_01_04_163311.csv.\n",
      "Meta-data was saved to: \n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/log_files/sim_data_2020_01_04_163311_log_file.txt.\n",
      "4500000 observations of simulation data created in 1 minutes and 27 seconds.\n",
      "Reconstituting data object from file.\n",
      "Successfully read in the .csv file specified at:\n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/sim_data_2020_01_04_163311.csv.\n",
      "/home/bknight/Documents/Power_Analysis_Techniques/v3/data/log_files/sim_data_2020_01_04_163311_log_file.txt\n",
      "Successfully read in the meta-data specified at:\n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/log_files/sim_data_2020_01_04_163311_log_file.txt.\n",
      "############## Starting value is n = 595,117.    ###########\n",
      "############## Starting adj. R-squared is 0.31. ###########\n",
      "/home/bknight/Documents/Power_Analysis_Techniques/v3/data\n",
      "The file sim_data_2020_01_04_163311.csv was deleted.\n",
      "The the associated meta-data for file sim_data_2020_01_04_163311.csv was also deleted.\n",
      "Starting value too high.\n",
      "1 additional covariates will be created.\n",
      "Now performing OLS to infer DGP parameters.\n",
      "Simulation data was saved to: \n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/sim_data_2020_01_04_163450.csv.\n",
      "Meta-data was saved to: \n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/log_files/sim_data_2020_01_04_163450_log_file.txt.\n",
      "4500000 observations of simulation data created in 0 minutes and 47 seconds.\n",
      "Reconstituting data object from file.\n",
      "Successfully read in the .csv file specified at:\n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/sim_data_2020_01_04_163450.csv.\n",
      "/home/bknight/Documents/Power_Analysis_Techniques/v3/data/log_files/sim_data_2020_01_04_163450_log_file.txt\n",
      "Successfully read in the meta-data specified at:\n",
      "     /home/bknight/Documents/Power_Analysis_Techniques/v3/data/log_files/sim_data_2020_01_04_163450_log_file.txt.\n",
      "############## Starting value is n = 378,222.    ###########\n",
      "############## Starting adj. R-squared is 0.0. ###########\n",
      "Estimating the effective power of n = 378,222 using 200 simulations.\n",
      "The effective power of sample size n = 378,222 is 61.19%.\n",
      "An upper-bound of n = 511,985 was specified.\n",
      "Estimating the effective power of n = 511,985 using 200 simulations.\n",
      "The effective power of sample size n = 511,985 is 61.19%.\n",
      "An upper-bound of n = 2,322,694 was specified.\n",
      "Estimating the effective power of n = 2,322,694 using 200 simulations.\n",
      "The effective power of sample size n = 2,322,694 is 100%.\n",
      "Estimating the effective power of n = 1,355,012 using 200 simulations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bknight/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2223: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effective power of sample size n = 1,355,012 is 100%.\n",
      "Estimating the effective power of n = 1,120,535 using 200 simulations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bknight/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2223: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effective power of sample size n = 1,120,535 is 96.52%.\n",
      "Estimating the effective power of n = 804,699 using 200 simulations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bknight/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2223: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effective power of sample size n = 804,699 is 83.58%.\n",
      "Estimating the effective power of n = 747,163 using 200 simulations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bknight/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2223: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dgps_analyzed = 0\n",
    "\n",
    "while dgps_analyzed < 2:\n",
    "    start = time.time()\n",
    "    dgp = sd.create_random_dgp(max_covariates             = 10, \n",
    "                               permissible_distributions  = ['normal', \n",
    "                                                             'exponential', \n",
    "                                                             'uniform'],\n",
    "                               range_of_normal_loc        = [50, 250], \n",
    "                               range_of_normal_scale      = [5, 25],\n",
    "                               range_of_exponential_scale = [0.5, 4],\n",
    "                               range_of_uniform           = [0,10],\n",
    "                               range_of_betas             = [0, 2.5],\n",
    "                               range_of_abs_mde           = [0.10, 0.20],\n",
    "                               range_of_noise_loc         = [25.0, 50.0],\n",
    "                               range_of_noise_scale       = [20.00, 35.00],\n",
    "                               sample_size                = 4500000)\n",
    "    pe_ob = pe.power_estimation(dgp)\n",
    "    print(\"############## Starting value is n = {:,}.    ###########\".format(pe_ob.starting_value))\n",
    "    print(\"############## Starting adj. R-squared is {}. ###########\".format(round(pe_ob.rsquared_adj,2)))\n",
    "    if pe_ob.starting_value > 475000: \n",
    "        sd.remove_data(dgp, drop_meta_data = True)\n",
    "        print(\"Starting value too high.\")\n",
    "        continue\n",
    "    if pe_ob.starting_value < 500: \n",
    "        sd.remove_data(dgp, drop_meta_data = True)\n",
    "        print(\"Starting value too low.\")\n",
    "        continue       \n",
    "    if pe_ob.rsquared_adj > 0.95:\n",
    "        sd.remove_data(dgp, drop_meta_data = True)\n",
    "        print(\"r-squared too high.\")\n",
    "        continue \n",
    "    \n",
    "    iso_ob = iso.isotonic(pe_ob)\n",
    "    n1, p1,  df1 = iso_ob.isotonic_interpolation()\n",
    "   \n",
    "    naive_bst = bst.binary_search(pe_ob, informed = 0)\n",
    "    n2, p2,  df2 = naive_bst.binary_search()\n",
    "\n",
    "    informed_bst = bst.binary_search(pe_ob, informed = 1)\n",
    "    n3, p3,  df3 = informed_bst.binary_search()\n",
    "    \n",
    "    pe.save_results(df1, iso_ob)\n",
    "    del iso_ob\n",
    "    pe.save_results(df2, naive_bst)\n",
    "    del naive_bst\n",
    "    pe.save_results(df3, informed_bst)\n",
    "    del informed_bst\n",
    "\n",
    "    dgps_analyzed += 1\n",
    "    sd.remove_data(dgp, drop_meta_data = False)\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    time_min = int(time_elapsed/60)\n",
    "    time_sec = int(time_elapsed - (time_min*60))\n",
    "    print(\"Assessment took {} minutes and {} seconds.\".format(time_min, time_sec))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, os.path\n",
    "\n",
    "files_found = len([name for name in os.listdir('./results/')])\n",
    "print(\"{} files were found in total.\".format(files_found))\n",
    "print(\"{} iterations.\".format(int(files_found/3)))\n",
    "isotonic_results        = []\n",
    "naive_binary_results    = []\n",
    "informed_binary_results = []\n",
    "[isotonic_results.append(name) for name in os.listdir('./results/') if \"isotonic\" in name]\n",
    "[naive_binary_results.append(name) for name in os.listdir('./results/') if \"naive_binary\" in name]\n",
    "[informed_binary_results.append(name) for name in os.listdir('./results/') if \"informed_binary\" in name]\n",
    "isotonic_results.sort()\n",
    "naive_binary_results.sort()\n",
    "informed_binary_results.sort()\n",
    "\n",
    "\n",
    "iso_sims, iso_time, iso_n = [], [], []\n",
    "for i in isotonic_results:\n",
    "    df = pd.read_csv('./results/' + i)\n",
    "    df['delta'] = abs(df['power'] - 0.8)\n",
    "    df.sort_values('delta',ascending=True, inplace=True)\n",
    "    n = df.iat[0,0]\n",
    "    iso_sims.append(df['sims_used'][0])\n",
    "    iso_time.append(df['seconds_used'][0])\n",
    "    iso_n.append(n)\n",
    "   # print(df)\n",
    "    \n",
    "naive_sims, naive_time, naive_n = [], [], []\n",
    "for j in naive_binary_results:\n",
    "    df = pd.read_csv('./results/' + j)\n",
    "    df['delta'] = abs(df['power'] - 0.8)\n",
    "    df.sort_values('delta',ascending=True, inplace=True)\n",
    "    n = df.iat[0,0]\n",
    "    naive_sims.append(df['sims_used'][0])\n",
    "    naive_time.append(df['seconds_used'][0])\n",
    "    naive_n.append(n)\n",
    "   # print(df)\n",
    "    \n",
    "informed_sims, informed_time, informed_n = [], [], []\n",
    "for k in informed_binary_results:\n",
    "    df = pd.read_csv('./results/' + k)\n",
    "    df['delta'] = abs(df['power'] - 0.8)\n",
    "    df.sort_values('delta',ascending=True, inplace=True)\n",
    "    n = df.iat[0,0]\n",
    "    informed_sims.append(df['sims_used'][0])\n",
    "    informed_time.append(df['seconds_used'][0])\n",
    "    informed_n.append(n)\n",
    "#     print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([iso_sims, iso_time, iso_n, \n",
    "                           naive_sims, naive_time, naive_n, \n",
    "                           informed_sims, informed_time, informed_n]).T\n",
    "results_df.columns = ['iso_sims', 'iso_time', 'iso_n', \n",
    "                      'naive_sims', 'naive_time', 'naive_n', \n",
    "                      'informed_sims', 'informed_time', 'informed_n']\n",
    "results_df.sort_values(by=['iso_n'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = results_df[ (results_df['iso_n'] <= 1000000)\n",
    "                   & (results_df['informed_n'] <= 1000000)\n",
    "                   & (results_df['naive_n'] <= 1000000)]\n",
    "subset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 4.8, forward=True)\n",
    "\n",
    "\n",
    "\n",
    "x1 = subset['iso_n']\n",
    "y1 = subset['iso_time']\n",
    "\n",
    "\n",
    "x2 = subset['informed_n']\n",
    "y2 = subset['informed_time']\n",
    "\n",
    "x3 = subset['naive_n'] \n",
    "y3 = subset['naive_time']\n",
    "\n",
    "sns.regplot(x1, y1, lowess=True, \n",
    "            color = '#b300b3', \n",
    "            marker='o', scatter_kws={'s':10})\n",
    "sns.regplot(x2, y2, lowess=True, \n",
    "            color = '#006600', \n",
    "            marker='o', scatter_kws={'s':10})\n",
    "sns.regplot(x3, y3, lowess=True, \n",
    "            color = '#3333cc', \n",
    "            marker='o', scatter_kws={'s':10})\n",
    "\n",
    "labels = [\n",
    "         'Isotonic Interpolation', \n",
    "         'Informed Binary Search', \n",
    "         'Naive Binary Search'\n",
    "         ]\n",
    "plt.legend(labels, prop={'size': 14})\n",
    "plt.ylabel('Estimation \\nTime \\nin \\nSeconds', size = 18).set_rotation(0)\n",
    "plt.xlabel('Estimated Sample Size Required', size = 18)\n",
    "plt.xlim(0,1000000)\n",
    "\n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,}'.format(int(x))))\n",
    "\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,}'.format(int(x))))\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.yaxis.set_label_coords(-0.16,0.35)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('v1.png',bbox_inches='tight')\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
